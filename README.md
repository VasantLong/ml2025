# ml2025

campus_ML

## 00

为什么需要机器学习

机器学习三要素

有监督：同样是问题和方法（分类问题 分类方法） 无监督

## 01

### 0102

决策树是什么

重要参数 4：控制模型复杂度，防止模型过拟合欠拟合

特征重要性 feature importance：特征值 反馈重复多次后得到一个稳定结果

### 0103

KNN 基本思路

近邻域

k=1 和 15 模型简单复杂？谁更容易受到周边数据影响

选哪个参数好：train 高的同时与 test 接近

### 0104

logistic

发生比含义

系数解释什么

### 0105

模型的偏差 方差：描述模型不确定性--追求双低的模型

偏差在现实中不容易计算

过拟合-高方差区 欠拟合-高偏差区

训练集 测试集 使用的原因

（集成学习 自助法）重复很多遍，增加模型复杂度不高 机器学习比统计受到数据量影响大

### 0106

SVM

原理：最大分割面

软间隔：分割面的边界模糊，松弛变量

核函数处理 投射高维空间：非线性变成线性

RBF 核

c γ 取值如何变化会让模型变复杂

数据归一化标准化：计算距离的模型必须要做，否则特征侧重大数

### 0107

模型评价

不平衡数据\*\*

解决方法：class weight

混淆矩阵

模型识别 对阳性数据特别关注 重点看 precision recall

F1 折中 precision recall

分类重点看 accuracy

多分类：借助二分类解决（一对其他、一对一）

宏平均、微平均

### 0108

交叉验证

- k 折

- 分层 k 折

- 打乱随机划分

- 时间序列

怎么选择

网格穷举法 grid search：穷举参数的组合数量、交叉验证的组合数量

### 0109

决策边界

precision-recall 曲线的识别分析

ROC 曲线分析

学习曲线分析：捕捉模型偏差的趋势

模型复杂度曲线

### 0110

神经网络

神经元的构成

网络结构

MLP 的结构：根据代码参数解读

α 控制模型拟合度 越大惩罚力度越强 灵活度越差 泛化能力越强

本身模型过拟合：让 hidden layer sizes 复杂度变小或者 α 变大

也需要归一化

### 0111

集成学习三大类

随机森林参数：如果过拟合，调参的方向是什么

特征重要性

GBDT

stacking 和其他两类的区别：异构

什么时候要使用

## 02

### 0201

数据伸缩：minmax standard robust

原则：训练集测试集一致性（需要识别出错误代码引用）

## 03

### 0301

降维

PCA 思路

为什么需要 PCA：降维+数据可视化

PCA 负载因子、主成分的含义

### 0303

分类和聚类区别

k-means 思路、失效的场合

凝聚聚类的几个连接函数

层聚类图判定分成积累

DBSCAN 概念

### 0304

聚类评估

兰德指数 计算

轮廓系数

## 04

概念稀碎，了解即可

## 05

### 0501

文本向量化

方法：词袋法、嵌入向量

词袋法：TF TF-IDF 次数

### 0503

情感分析
